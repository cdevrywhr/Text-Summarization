{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import operator\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def load_stopWords():\n",
    "    f = open('stopword_list.txt', 'r')\n",
    "    return f.readlines()\n",
    "\n",
    "stopwords = load_stopWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(sentence):\n",
    "    ret = []\n",
    "    sentence = stemmer.stem(sentence)\n",
    "    for word in sentence.split():\n",
    "        if not word in stopwords:\n",
    "            ret.append(word)\n",
    "    return \" \".join(ret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVectorSpace(cleanSet):\n",
    "    vocab = {}\n",
    "    for data in cleanSet:\n",
    "        for word in data.split():\n",
    "            vocab[data] = 0\n",
    "    return vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateSimilarity(sentence, doc):\n",
    "    if doc == []:\n",
    "        return 0\n",
    "    vocab = {}\n",
    "    for word in sentence:\n",
    "        vocab[word] = 0\n",
    "\n",
    "    docInOneSentence = ''\n",
    "    for t in doc:\n",
    "        docInOneSentence += (t + ' ')\n",
    "        for word in t.split():\n",
    "            vocab[word]=0\n",
    "    \n",
    "    cv = CountVectorizer(vocabulary=vocab.keys())\n",
    "\n",
    "    docVector = cv.fit_transform([docInOneSentence])\n",
    "    sentenceVector = cv.fit_transform([sentence])\n",
    "    return cosine_similarity(docVector, sentenceVector)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('news_data.txt', 'r')\n",
    "texts = data.readlines()\n",
    "\n",
    "sentences = []\n",
    "clean  = []\n",
    "originalSentenceOf = {}\n",
    "\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in texts:\n",
    "    parts = line.split('.')\n",
    "    for part in parts:\n",
    "        cl = cleanData(part)\n",
    "        #print cl\n",
    "        sentences.append(part)\n",
    "        clean.append(cl)\n",
    "        originalSentenceOf[cl] = part\n",
    "setClean = set(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for data in clean:\n",
    "    temp_doc = setClean - set([data])\n",
    "    score = calculateSimilarity(data, list(temp_doc))\n",
    "    scores[data] = score\n",
    "    #print score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20 * len(sentences)/100\n",
    "alpha = 0.5\n",
    "summarySet = []\n",
    "while n > 0:\n",
    "    mmr = {}\n",
    "    #kurangkan dengan set summary\n",
    "    for sentence in scores.keys():\n",
    "        if not sentence in summarySet:\n",
    "            mmr[sentence] = alpha * scores[sentence] - (1-alpha) * calculateSimilarity(sentence, summarySet)\n",
    "            selected = max(mmr.items(), key=operator.itemgetter(1))[0]\n",
    "            summarySet.append(selected)\n",
    "            n -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nRingaksan : \\n')\n",
    "for sentence in summarySet:\n",
    "    print(originalSentenceOf[sentence].lstrip(' '))\n",
    "print\n",
    "print('============================================')\n",
    "print('\\nDokumen asli : \\n')\n",
    "\n",
    "for sentence in clean:\n",
    "    if sentence in summarySet:\n",
    "        print(colored(originalSentenceOf[sentence].lstrip(' '), 'red'))\n",
    "    else:\n",
    "        print(originalSentenceOf[sentence].lstrip(' '))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38264bit40c6fe10cef94c4693365092fefcad47",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}